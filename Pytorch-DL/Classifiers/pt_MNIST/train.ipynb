{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import torchmetrics\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "from dataloader import LoadData\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from models.CNN import CNN\n",
    "from models.DNN import DNN\n",
    "\n",
    "import yaml\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.load(open(\"./config.yaml\", \"r\"), Loader=yaml.FullLoader)\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data = LoadData(config)\n",
    "    \n",
    "train_dataloader = load_data.train_dataloader()\n",
    "val_dataloader = load_data.val_dataloader()\n",
    "test_dataloader =load_data.test_dataloader()\n",
    "predict_dataloader = load_data.predict_dataloader()\n",
    "\n",
    "accuracy=torchmetrics.classification.MulticlassAccuracy(num_classes = 10).to(DEVICE)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = config[\"model\"][\"model_name\"]\n",
    "if model_name==\"CNN\":\n",
    "    model=CNN(config)\n",
    "elif model_name=='DNN':\n",
    "    model=DNN(config)\n",
    "elif model_name==\"RESNET\":\n",
    "    model=RESNET()\n",
    "else:\n",
    "    print(\"No model\")\n",
    "    sys.exit()\n",
    "    \n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Loss & 4. Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, optimizer, log_interval = 5):\n",
    "    model.train()\n",
    "    for batch_idx, (x, y) in enumerate(train_dataloader):\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        y_hat = model(x)\n",
    "        loss = criterion(y_hat, y)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f\"Train Epoch: {Epochs} [{batch_idx*len(x)}/{len(train_dataloader.dataset)}({100*batch_idx/len(train_dataloader):.0f}%)]\\tTrain Loss: {loss.item():.6f}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model, test_dataloader):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in test_dataloader:\n",
    "            x = x.to(DEVICE)\n",
    "            y = y.to(DEVICE)\n",
    "            y_hat = model(x)\n",
    "            \n",
    "            loss +=criterion(y_hat,y).item()\n",
    "            accuracy(y_hat,y)\n",
    "           \n",
    "    loss /= len(test_dataloader.dataset)\n",
    "    \n",
    "    acc = accuracy.compute()\n",
    "    accuracy.reset()\n",
    "    return loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/55000(0%)]\tTrain Loss: 2.299160\n",
      "Train Epoch: 1 [6400/55000(12%)]\tTrain Loss: 0.178778\n",
      "Train Epoch: 1 [12800/55000(23%)]\tTrain Loss: 0.122540\n",
      "Train Epoch: 1 [19200/55000(35%)]\tTrain Loss: 0.134331\n",
      "Train Epoch: 1 [25600/55000(47%)]\tTrain Loss: 0.113129\n",
      "Train Epoch: 1 [32000/55000(58%)]\tTrain Loss: 0.150258\n",
      "Train Epoch: 1 [38400/55000(70%)]\tTrain Loss: 0.034891\n",
      "Train Epoch: 1 [44800/55000(81%)]\tTrain Loss: 0.056065\n",
      "Train Epoch: 1 [51200/55000(93%)]\tTrain Loss: 0.007461\n",
      "\n",
      "[Epoch: 1], \tval Loss: 0.0024\tval Accuracy: 0.9764\n",
      "Train Epoch: 2 [0/55000(0%)]\tTrain Loss: 0.155444\n",
      "Train Epoch: 2 [6400/55000(12%)]\tTrain Loss: 0.029929\n",
      "Train Epoch: 2 [12800/55000(23%)]\tTrain Loss: 0.004255\n",
      "Train Epoch: 2 [19200/55000(35%)]\tTrain Loss: 0.108144\n",
      "Train Epoch: 2 [25600/55000(47%)]\tTrain Loss: 0.008648\n",
      "Train Epoch: 2 [32000/55000(58%)]\tTrain Loss: 0.003399\n",
      "Train Epoch: 2 [38400/55000(70%)]\tTrain Loss: 0.041789\n",
      "Train Epoch: 2 [44800/55000(81%)]\tTrain Loss: 0.000698\n",
      "Train Epoch: 2 [51200/55000(93%)]\tTrain Loss: 0.115554\n",
      "\n",
      "[Epoch: 2], \tval Loss: 0.0013\tval Accuracy: 0.9864\n",
      "Train Epoch: 3 [0/55000(0%)]\tTrain Loss: 0.004253\n",
      "Train Epoch: 3 [6400/55000(12%)]\tTrain Loss: 0.005852\n",
      "Train Epoch: 3 [12800/55000(23%)]\tTrain Loss: 0.065026\n",
      "Train Epoch: 3 [19200/55000(35%)]\tTrain Loss: 0.139112\n",
      "Train Epoch: 3 [25600/55000(47%)]\tTrain Loss: 0.054149\n",
      "Train Epoch: 3 [32000/55000(58%)]\tTrain Loss: 0.043004\n",
      "Train Epoch: 3 [38400/55000(70%)]\tTrain Loss: 0.017709\n",
      "Train Epoch: 3 [44800/55000(81%)]\tTrain Loss: 0.000333\n",
      "Train Epoch: 3 [51200/55000(93%)]\tTrain Loss: 0.009480\n",
      "\n",
      "[Epoch: 3], \tval Loss: 0.0014\tval Accuracy: 0.9889\n"
     ]
    }
   ],
   "source": [
    "max_epochs = config['train']['max_epochs']\n",
    "\n",
    "for Epochs in range(1, max_epochs+1):\n",
    "    train(model, train_dataloader, optimizer, log_interval = 200)\n",
    "    val_loss, val_acc = eval(model, val_dataloader)\n",
    "    print(f\"\\n[Epoch: {Epochs}], \\tval Loss: {val_loss:.4f}\\tval Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "model_save_path = config[\"train\"][\"model_save_dir\"] + \"/model_state_dict.pt\"\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00859987735748291\n",
      "0.011519250925630331\n",
      "0.01368005876429379\n",
      "0.018931448692455888\n",
      "0.019067008266574703\n",
      "0.0213104209251469\n",
      "0.0225982981355628\n",
      "0.05101049678341951\n",
      "0.05787212435097899\n",
      "0.05875138942792546\n",
      "0.14035630975558888\n",
      "0.14523381930484902\n",
      "0.14696136424026918\n",
      "0.20175264710269403\n",
      "0.26559511506638955\n",
      "0.2661702695040731\n",
      "0.2663410475652199\n",
      "0.269482822594\n",
      "0.36910089987213723\n",
      "0.37003596129943617\n",
      "0.39011713679064997\n",
      "0.4423534367524553\n",
      "0.4744872730516363\n",
      "0.5838699993037153\n",
      "0.5851518053386826\n",
      "0.5863291772839148\n",
      "0.6092384311195929\n",
      "0.6353109947231133\n",
      "0.7291340849187691\n",
      "0.9949747643258888\n",
      "1.030600650497945\n",
      "1.1938142015424091\n",
      "1.2226635387924034\n",
      "1.2228919051995035\n",
      "1.2254705469531473\n",
      "1.2338967168179806\n",
      "1.3013141372648533\n",
      "1.3023082420404535\n",
      "1.49952140005189\n",
      "1.5726629153068643\n",
      "1.6272334002132993\n",
      "1.6300430011178833\n",
      "1.6312518475751858\n",
      "1.6434085780929308\n",
      "1.648410976602463\n",
      "1.7163199491042178\n",
      "1.718535733380122\n",
      "1.8294323356531095\n",
      "1.8372714426077437\n",
      "1.8376512564136647\n",
      "1.8738291374756955\n",
      "1.8854574933066033\n",
      "1.9209593086852692\n",
      "1.936308468633797\n",
      "1.9437071834108792\n",
      "2.0442436714074574\n",
      "2.04899792507058\n",
      "2.0494056576280855\n",
      "2.0752404638915323\n",
      "2.279271678009536\n",
      "2.280504649213981\n",
      "2.3051990547101013\n",
      "2.3065126906731166\n",
      "2.4442714076139964\n",
      "2.4501884333440103\n",
      "2.4643564089783467\n",
      "2.7222171589382924\n",
      "2.730767955596093\n",
      "2.766497747565154\n",
      "2.7729715589084662\n",
      "2.7741585750482045\n",
      "2.801162567397114\n",
      "2.8020895730587654\n",
      "2.8040198705275543\n",
      "2.8120411069248803\n",
      "2.8215774803538807\n",
      "3.066906011023093\n",
      "3.0674076576251537\n",
      "3.068412404623814\n",
      "3.0693303717998788\n",
      "3.076787337078713\n",
      "3.2746879452606663\n",
      "3.5984997445484623\n",
      "3.604145069955848\n",
      "3.6089019224746153\n",
      "3.6106585344532505\n",
      "3.6725141821661964\n",
      "3.6727990835206583\n",
      "3.674373400164768\n",
      "3.6757640287978575\n",
      "3.686049049603753\n",
      "3.7387988622067496\n",
      "3.7466450788779184\n",
      "3.7575786717934534\n",
      "3.7618303791387007\n",
      "3.772962443414144\n",
      "3.803641766193323\n",
      "3.806053130538203\n",
      "3.807311777258292\n",
      "3.809232876985334\n",
      "3.9001485047629103\n",
      "3.9056367905577645\n",
      "3.991769957705401\n",
      "3.9920662410440855\n",
      "4.000128323386889\n",
      "4.007870530418586\n",
      "4.140097101859283\n",
      "4.170277766592335\n",
      "4.1714061318780296\n",
      "4.207338583364617\n",
      "4.262173206254374\n",
      "4.297650170221459\n",
      "4.300929612654727\n",
      "4.301127519196598\n",
      "4.302518943528412\n",
      "4.312611112574814\n",
      "4.393109249154804\n",
      "4.437562706152676\n",
      "4.474946489761351\n",
      "4.521546410600422\n",
      "4.5362570008437615\n",
      "4.536794953019125\n",
      "4.550696289137704\n",
      "4.625702893332345\n",
      "4.638812695600791\n",
      "4.648763578356011\n",
      "4.654257072106702\n",
      "4.657639922777889\n",
      "4.660154022247298\n",
      "4.660282760771224\n",
      "4.834971681149909\n",
      "4.853881871240446\n",
      "4.859685883304337\n",
      "4.874717835715273\n",
      "4.880783909378806\n",
      "4.881802980002249\n",
      "4.924773443635786\n",
      "4.977966096397722\n",
      "4.979527754156152\n",
      "4.9801532879064325\n",
      "5.126537705917144\n",
      "5.15403243448236\n",
      "5.158603848103667\n",
      "5.163878424704308\n",
      "5.2570053773524705\n",
      "5.257238426522235\n",
      "5.265912093498628\n",
      "5.321572959699552\n",
      "5.390255481281201\n",
      "5.405508846321027\n",
      "5.523186989405076\n",
      "5.729418076851289\n",
      "5.736567099389504\n",
      "5.73883381257474\n",
      "5.744394752240623\n",
      "5.748682092453237\n",
      "5.748914191164658\n",
      "5.748919730595389\n",
      "5.75216170219619\n",
      "5.752206789937645\n",
      "5.766151426968008\n",
      "5.769294655791327\n",
      "5.77009806493561\n",
      "5.7703332051137295\n",
      "5.770562504240388\n",
      "5.783076048650855\n",
      "5.783160167037295\n",
      "5.783174081894231\n",
      "5.783890698293817\n",
      "5.7839283922508\n",
      "5.804381992463732\n",
      "5.804387371555549\n",
      "5.804642681357564\n",
      "5.804750148568473\n",
      "5.8047947965001185\n",
      "5.807842699335652\n",
      "5.842754506962137\n",
      "5.8433224146624525\n",
      "5.843420413953481\n",
      "5.8492786806796175\n",
      "5.849287579989777\n",
      "5.850029567537149\n",
      "5.850607952558221\n",
      "5.851887462883042\n",
      "5.852350379650034\n",
      "5.861774514738954\n",
      "5.9571439729375015\n",
      "5.996302775417007\n",
      "5.999628239620961\n",
      "6.005531706225611\n",
      "6.005790707266442\n",
      "6.005807727341107\n",
      "6.006391656467258\n",
      "6.006433262230075\n",
      "6.006435571886186\n",
      "6.00643701728859\n",
      "6.0064376170594755\n",
      "6.006441319892076\n",
      "6.00645598092575\n",
      "6.006495132933708\n",
      "6.008207085433753\n",
      "6.00820976017377\n",
      "6.008857391531194\n",
      "6.009090512471005\n",
      "6.22603535600166\n",
      "6.403582602219387\n",
      "6.878873913960263\n",
      "6.950505338089272\n",
      "6.9525202877742345\n",
      "6.953069315586902\n",
      "6.958151384551741\n",
      "7.06357556517861\n",
      "7.0670367966561685\n",
      "7.067280550112912\n",
      "7.067290637249528\n",
      "7.067555048517818\n",
      "7.067570079357495\n",
      "7.067738057382769\n",
      "7.067766409621356\n",
      "7.068071978420733\n",
      "7.069058363230681\n",
      "7.0727556577397195\n",
      "7.101680886603674\n",
      "7.101813084859998\n",
      "7.102014887167854\n",
      "7.138343258782072\n",
      "7.139487968429705\n",
      "7.139761706195088\n",
      "7.139798603271004\n",
      "7.14258838586403\n",
      "7.143136462563518\n",
      "7.143297508347416\n",
      "7.143800428998759\n",
      "7.144590063067255\n",
      "7.145158860937329\n",
      "7.145336640332346\n",
      "7.14691639892709\n",
      "7.148505422318806\n",
      "7.150489699593265\n",
      "7.1505218553168675\n",
      "7.150531894353946\n",
      "7.150677082726645\n",
      "7.150688299118258\n",
      "7.1507494122727735\n",
      "7.152105131559722\n",
      "7.166127909348063\n",
      "7.166581373656584\n",
      "7.168754728505803\n",
      "7.168782496785127\n",
      "7.171222757741191\n",
      "7.171631617693777\n",
      "7.195161976142401\n",
      "7.259313926322932\n",
      "7.262500664907122\n",
      "7.262557943402783\n",
      "7.264290217361406\n",
      "7.264846511760254\n",
      "7.297214627841015\n",
      "7.298139078768429\n",
      "7.298500555502244\n",
      "7.3074345681164345\n",
      "7.30838921170681\n",
      "7.397503222040825\n",
      "7.397509007264318\n",
      "7.397532577015966\n",
      "7.398400842533022\n",
      "7.471858657286077\n",
      "7.471864345677943\n",
      "7.471951751654899\n",
      "7.472573537122855\n",
      "7.472876174875466\n",
      "7.4728783541523285\n",
      "7.472881479631326\n",
      "7.47308403488438\n",
      "7.4730863258928935\n",
      "7.473199608776724\n",
      "7.473212458917317\n",
      "7.473217517717842\n",
      "7.473224722035013\n",
      "7.4733173099926375\n",
      "7.4747230986945965\n",
      "7.476288909802463\n",
      "7.476462830364255\n",
      "7.476558651335438\n",
      "7.476601025261118\n",
      "7.4770960341525665\n",
      "7.47778752271239\n",
      "7.478198022141953\n",
      "7.478269033785693\n",
      "7.478348851593694\n",
      "7.4783912278404046\n",
      "7.4786309892556915\n",
      "7.4793079403357865\n",
      "7.479541290497366\n",
      "7.4798235828389465\n",
      "7.479937944543565\n",
      "7.480695528309809\n",
      "7.486555925436335\n",
      "7.488811191502975\n",
      "7.489393545180576\n",
      "7.492103914130496\n",
      "7.5157517868615855\n",
      "7.8086280602552165\n",
      "7.811475196253525\n",
      "7.9643131730668415\n",
      "7.992821381758915\n",
      "8.016498440276848\n",
      "8.030737951729463\n",
      "8.035617529746162\n",
      "8.070416211482154\n",
      "8.074797454155998\n",
      "8.077666730253043\n",
      "8.07790383731168\n",
      "Test Loss: 0.0008\tTest Accuracy: 0.9915\n"
     ]
    }
   ],
   "source": [
    "model_name = config[\"model\"][\"model_name\"]\n",
    "if model_name==\"CNN\":\n",
    "    model=CNN(config)\n",
    "elif model_name=='DNN':\n",
    "    model=DNN(config)\n",
    "elif model_name==\"RESNET\":\n",
    "    model=RESNET()\n",
    "else:\n",
    "    print(\"No model\")\n",
    "    sys.exit()\n",
    "    \n",
    "model = model.to(DEVICE)\n",
    "\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "test_loss, test_acc = eval(model, test_dataloader)\n",
    "print(f\"Test Loss: {test_loss:.4f}\\tTest Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zeroone_univ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
