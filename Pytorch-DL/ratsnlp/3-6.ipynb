{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFt_JLYoTKA6"
      },
      "source": [
        "## 토크나이저 초기화\n",
        "\n",
        "BERT(`kcbert-base`) 모델이 쓰는 토크나이저를 선언합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bThW-2OrTHZW"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/youngwon/anaconda3/envs/nlp_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "2023-04-13 19:23:44.219792: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-13 19:23:44.881730: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Downloading: 100%|██████████| 250k/250k [00:00<00:00, 1.07MB/s]\n",
            "Downloading: 100%|██████████| 49.0/49.0 [00:00<00:00, 49.0kB/s]\n",
            "Downloading: 100%|██████████| 619/619 [00:00<00:00, 636kB/s]\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    \"beomi/kcbert-base\",\n",
        "    do_lower_case=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0NCnzpRTdnJ"
      },
      "source": [
        "## 모델 초기화\n",
        "\n",
        "BERT(`kcbert-base`) 모델을 읽어들입니다. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FSVDbnFUTiXx"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: 100%|██████████| 438M/438M [06:27<00:00, 1.13MB/s] \n",
            "Some weights of the model checkpoint at beomi/kcbert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertConfig, BertModel\n",
        "pretrained_model_config = BertConfig.from_pretrained(\n",
        "    \"beomi/kcbert-base\"\n",
        ")\n",
        "model = BertModel.from_pretrained(\n",
        "    \"beomi/kcbert-base\",\n",
        "    config=pretrained_model_config,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWboOauTTyXp"
      },
      "source": [
        "`pretrained_model_config`의 내용을 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tup5LreLT4vE"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertConfig {\n",
              "  \"_name_or_path\": \"beomi/kcbert-base\",\n",
              "  \"architectures\": [\n",
              "    \"BertForMaskedLM\"\n",
              "  ],\n",
              "  \"attention_probs_dropout_prob\": 0.1,\n",
              "  \"classifier_dropout\": null,\n",
              "  \"directionality\": \"bidi\",\n",
              "  \"gradient_checkpointing\": false,\n",
              "  \"hidden_act\": \"gelu\",\n",
              "  \"hidden_dropout_prob\": 0.1,\n",
              "  \"hidden_size\": 768,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 3072,\n",
              "  \"layer_norm_eps\": 1e-12,\n",
              "  \"max_position_embeddings\": 300,\n",
              "  \"model_type\": \"bert\",\n",
              "  \"num_attention_heads\": 12,\n",
              "  \"num_hidden_layers\": 12,\n",
              "  \"pad_token_id\": 0,\n",
              "  \"pooler_fc_size\": 768,\n",
              "  \"pooler_num_attention_heads\": 12,\n",
              "  \"pooler_num_fc_layers\": 3,\n",
              "  \"pooler_size_per_head\": 128,\n",
              "  \"pooler_type\": \"first_token_transform\",\n",
              "  \"position_embedding_type\": \"absolute\",\n",
              "  \"transformers_version\": \"4.10.0\",\n",
              "  \"type_vocab_size\": 2,\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 30000\n",
              "}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pretrained_model_config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y2JYqRGUFll"
      },
      "source": [
        "## 모델 입력값 만들기\n",
        "\n",
        "문장 2개를 모델 입력값으로 만들어보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "9Rk2Ga65USFb"
      },
      "outputs": [],
      "source": [
        "sentences = [\"안녕하세요\", \"하이!\", \"우리의 정원은 아름답다.\"]\n",
        "features = tokenizer(\n",
        "    sentences,\n",
        "    max_length=10,\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLq1JRVJUb7U"
      },
      "source": [
        "`features`의 내용을 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "XZl8OKdsVIQg"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "LzkJ31vQVbjl"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[2, 19017, 8482, 3, 0, 0, 0, 0, 0, 0],\n",
              " [2, 15830, 5, 3, 0, 0, 0, 0, 0, 0],\n",
              " [2, 10293, 2539, 10480, 13213, 12108, 17, 3, 0, 0]]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features['input_ids']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Lc_71OjafQgS"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
              " [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
              " [1, 1, 1, 1, 1, 1, 1, 1, 0, 0]]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features['attention_mask']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Fdv1TGOHfQpm"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features['token_type_ids']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wR-3V6zIVsPp"
      },
      "source": [
        "## BERT 임베딩 추출\n",
        "\n",
        "위에서 만든 `features`를 파이토치 텐서(tensor)로 변환합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "FdvUPuJoV3w3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "features = {k: torch.tensor(v) for k, v in features.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[    2, 19017,  8482,     3,     0,     0,     0,     0,     0,     0],\n",
              "         [    2, 15830,     5,     3,     0,     0,     0,     0,     0,     0],\n",
              "         [    2, 10293,  2539, 10480, 13213, 12108,    17,     3,     0,     0]]),\n",
              " 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
              " 'attention_mask': tensor([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
              "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0S2EbdkWIdq"
      },
      "source": [
        "BERT 모델에 `features`를 입력해 계산합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "YOWkywHaWOL6"
      },
      "outputs": [],
      "source": [
        "outputs = model(**features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fog_9z0SqHog"
      },
      "source": [
        "BERT 마지막 레이어의 단어 수준 벡터들을 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "-wRQNlJMqMjh"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 10, 768])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "outputs.last_hidden_state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwDi0WNdrG7r"
      },
      "source": [
        "BERT 마지막 레이어의 문서 수준 벡터를 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "0FQ1nayZrLQl"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.1594,  0.0547,  0.1101,  ...,  0.2684,  0.1596, -0.9828],\n",
              "        [-0.9221,  0.2969, -0.0110,  ...,  0.4291,  0.0311, -0.9955],\n",
              "        [-0.3893, -0.1339, -0.2305,  ...,  0.1188,  0.1195,  0.3018]],\n",
              "       grad_fn=<TanhBackward0>)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "outputs.pooler_output"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "embedding.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
