{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 10. GAN\n",
    "Fashion MNIST 데이터를 처리하는 GAN 모델을 만들어 보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 0. 이것저것 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from utilities import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_R = 1e-3\n",
    "BATCH_SIZE = 100\n",
    "EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available()==True:\n",
    "  DEVICE='cuda'\n",
    "else:\n",
    "  DEVICE='cpu'\n",
    "np.random.seed(0b011011)\n",
    "random.seed(0b011011)\n",
    "torch.manual_seed(0b011011)\n",
    "if DEVICE == 'cuda':\n",
    "  torch.cuda.manual_seed_all(0b011011)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"F:\\Python_Codes\\Data_for_Practice\", \n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=ToTensor()\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "test_data= datasets.FashionMNIST(\n",
    "    root=\"F:\\Python_Codes\\Data_for_Practice\", \n",
    "    train=False, \n",
    "    download=True, \n",
    "    transform=ToTensor()\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader =DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader =DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim=100, img_shape=(28,28)):\n",
    "        self.latent_dim=latent_dim\n",
    "        self.img_shape=img_shape\n",
    "        super(Generator,self).__init__()\n",
    "\n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers=[nn.Linear(in_feat,out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat))\n",
    "            layers.append(nn.ReLU())\n",
    "            return layers\n",
    "\n",
    "        self.model= nn.Sequential(\n",
    "            *block(self.latent_dim,128, normalize=False),\n",
    "            *block(128,256),\n",
    "            *block(256,512),\n",
    "            *block(512,1024),\n",
    "            nn.Linear(1024, int(np.prod(img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self,z):\n",
    "        img=self.model(z)\n",
    "        img=img.view(img.size(0),*img_shape)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_shape=(28,28)):\n",
    "        super(Discriminator,self).__init__()\n",
    "    \n",
    "        self.model=nn.Sequential(\n",
    "            nn.Linear(int(np.prod(img_shape)),512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self,img):\n",
    "        img=img.view(img.size(0),-1)\n",
    "        out=self.model(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen=Generator().to(DEVICE)\n",
    "dis=Discriminator().to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3 and 4. Loss and Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "advloss_fn=nn.BCELoss().to(DEVICE)\n",
    "\n",
    "G_opt = torch.optim.Adam(gen.parameters(), lr=L_R)\n",
    "D_opt = torch.optim.Adam(dis.parameters(), lr=L_R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, generator, discriminator, advloss_fn, G_opt, D_opt):\n",
    "    gen_avgloss=0\n",
    "    dis_avgloss=0\n",
    "    for i, (imgs,_) in enumerate(dataloader):\n",
    "        imgs=imgs.to(DEVICE)\n",
    "        valid=torch.Tensor(imgs.size(0),1, requires_grad=False).fill_(1.0).to(DEVICE)\n",
    "        fake=torch.Tensor(imgs.size(0),0, requires_grad=False).fill_(0.0).to(DEVICE)\n",
    "\n",
    "        #Train Generator\n",
    "        G_opt.zero_grad()\n",
    "\n",
    "        z=Tensor(np.random.normal(0,1,(imgs.shape[0], 100))).to(DEVICE)\n",
    "        gen_imgs=generator(z)\n",
    "        \n",
    "        g_loss=advloss_fn(discriminator(gen_img),valid)\n",
    "        gen_avgloss+=g_loss\n",
    "        g_loss.backward()\n",
    "        G_opt.step()\n",
    "       \n",
    "        #Train Discriminator\n",
    "        real_loss=advloss_fn(discriminator(real_imgs), valid)\n",
    "        fake_loss=advloss_fn(discriminator(gen_imgs.detach()),fake)\n",
    "\n",
    "        d_loss=(real_loss+fake_loss)/2\n",
    "        dis_avgloss+=d_loss\n",
    "        d_loss.backward()\n",
    "        D_opt.step()\n",
    "    return gen_avgloss.item()/len(dataloader), dis_avgloss.item()/len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new() received an invalid combination of arguments - got (int, int, requires_grad=bool), but expected one of:\n * (*, torch.device device)\n * (torch.Storage storage)\n * (Tensor other)\n * (tuple of ints size, *, torch.device device)\n      didn't match because some of the keywords were incorrect: requires_grad\n * (object data, *, torch.device device)\n      didn't match because some of the keywords were incorrect: requires_grad\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp/ipykernel_27188/1115236439.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mgen_avgloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdis_avgloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDiscriminator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madvloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mG_opt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD_opt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     print(\n\u001b[0;32m      4\u001b[0m             \u001b[1;34m\"[Epoch %d/%d]  [D loss: %f] [G loss: %f]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdis_avgloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_avgloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp/ipykernel_27188/4138629514.py\u001b[0m in \u001b[0;36mtrain_loop\u001b[1;34m(dataloader, generator, discriminator, advloss_fn, G_opt, D_opt)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mimgs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mvalid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mfake\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: new() received an invalid combination of arguments - got (int, int, requires_grad=bool), but expected one of:\n * (*, torch.device device)\n * (torch.Storage storage)\n * (Tensor other)\n * (tuple of ints size, *, torch.device device)\n      didn't match because some of the keywords were incorrect: requires_grad\n * (object data, *, torch.device device)\n      didn't match because some of the keywords were incorrect: requires_grad\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    gen_avgloss, dis_avgloss=train_loop(train_loader, Generator, Discriminator, advloss_fn, G_opt, D_opt)\n",
    "    print(\n",
    "            \"[Epoch %d/%d]  [D loss: %f] [G loss: %f]\"\n",
    "            % (epoch, EPOCHS, dis_avgloss.item(), gen_avgloss.item())\n",
    "        )\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dca4efdd400e53e6663797bbd1b46cf726b4dffb9a4cd6e80b88fc0d122f2781"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('pytorch_env': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
