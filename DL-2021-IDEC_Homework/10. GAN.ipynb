{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Lecture 10. GAN\r\n",
    "Fashion MNIST 데이터를 처리하는 GAN 모델을 만들어 보자"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 0. 이것저것 준비"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "from torch import nn\r\n",
    "from torch.utils.data import Dataset, DataLoader\r\n",
    "\r\n",
    "from torchvision import datasets\r\n",
    "from torchvision.transforms import ToTensor\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import torch.nn.functional as F\r\n",
    "from torch.utils.tensorboard import SummaryWriter\r\n",
    "\r\n",
    "import random\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "from utilities import EarlyStopping"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorboard'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-40150539ee60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensorboard\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\utils\\tensorboard\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msetuptools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mLooseVersion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdistutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLooseVersion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorboard'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "L_R = 1e-3\r\n",
    "BATCH_SIZE = 100\r\n",
    "EPOCHS = 200"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "if torch.cuda.is_available()==True:\r\n",
    "  DEVICE='cuda'\r\n",
    "else:\r\n",
    "  DEVICE='cpu'\r\n",
    "np.random.seed(0b011011)\r\n",
    "random.seed(0b011011)\r\n",
    "torch.manual_seed(0b011011)\r\n",
    "if DEVICE == 'cuda':\r\n",
    "  torch.cuda.manual_seed_all(0b011011)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 1. Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "train_data = datasets.FashionMNIST(\r\n",
    "    root=\"F:\\Python_Codes\\Data_for_Practice\", \r\n",
    "    train=True, \r\n",
    "    download=True, \r\n",
    "    transform=ToTensor()\r\n",
    "    )\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "test_data= datasets.FashionMNIST(\r\n",
    "    root=\"F:\\Python_Codes\\Data_for_Practice\", \r\n",
    "    train=False, \r\n",
    "    download=True, \r\n",
    "    transform=ToTensor()\r\n",
    "    )\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\pytorch_env\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "train_loader =DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\r\n",
    "test_loader =DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 2. Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "class Generator(nn.Module):\r\n",
    "    def __init__(self, latent_dim=100, img_shape=(28,28)):\r\n",
    "        self.latent_dim=latent_dim\r\n",
    "        self.img_shape=img_shape\r\n",
    "        super(Generator,self).__init__()\r\n",
    "\r\n",
    "        def block(in_feat, out_feat, normalize=True):\r\n",
    "            layers=[nn.Linear(in_feat,out_feat)]\r\n",
    "            if normalize:\r\n",
    "                layers.append(nn.BatchNorm1d(out_feat))\r\n",
    "            layers.append(nn.ReLU())\r\n",
    "            return layers\r\n",
    "\r\n",
    "        self.model= nn.Sequential(\r\n",
    "            *block(self.latent_dim,128, normalize=False),\r\n",
    "            *block(128,256),\r\n",
    "            *block(256,512),\r\n",
    "            *block(512,1024),\r\n",
    "            nn.Linear(1024, int(np.prod(img_shape))),\r\n",
    "            nn.Tanh()\r\n",
    "        )\r\n",
    "    \r\n",
    "    def forward(self,z):\r\n",
    "        img=self.model(z)\r\n",
    "        img=img.view(img.size(0),*img_shape)\r\n",
    "        return img"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "class Discriminator(nn.Module):\r\n",
    "    def __init__(self, img_shape=(28,28)):\r\n",
    "        super(Discriminator,self).__init__()\r\n",
    "    \r\n",
    "        self.model=nn.Sequential(\r\n",
    "            nn.Linear(int(np.prod(img_shape)),512),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Linear(512, 256),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Linear(256,1),\r\n",
    "            nn.Sigmoid()\r\n",
    "        )\r\n",
    "\r\n",
    "    def forward(self,img):\r\n",
    "        img=img.view(img.size(0),-1)\r\n",
    "        out=self.model(img)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "gen=Generator().to(DEVICE)\r\n",
    "dis=Discriminator().to(DEVICE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 3 and 4. Loss and Optimization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "advloss_fn=nn.BCELoss().to(DEVICE)\r\n",
    "\r\n",
    "G_opt = torch.optim.Adam(gen.parameters(), lr=L_R)\r\n",
    "D_opt = torch.optim.Adam(dis.parameters(), lr=L_R)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "def train_loop(dataloader, generator, discriminator, advloss_fn, G_opt, D_opt):\r\n",
    "    gen_avgloss=0\r\n",
    "    dis_avgloss=0\r\n",
    "    for i, (imgs,_) in enumerate(dataloader):\r\n",
    "        imgs=imgs.to(DEVICE)\r\n",
    "        valid=torch.Tensor(imgs.size(0),1).fill_(1.0, requires_grad=False).to(DEVICE)\r\n",
    "        fake=torch.Tensor(imgs.size(0),0).fill_(0.0, requires_grad=False).to(DEVICE)\r\n",
    "\r\n",
    "        #Train Generator\r\n",
    "        G_opt.zero_grad()\r\n",
    "\r\n",
    "        z=Tensor(np.random.normal(0,1,(imgs.shape[0], 100))).to(DEVICE)\r\n",
    "        gen_imgs=generator(z)\r\n",
    "        \r\n",
    "        g_loss=advloss_fn(discriminator(gen_img),valid)\r\n",
    "        gen_avgloss+=g_loss\r\n",
    "        g_loss.backward()\r\n",
    "        G_opt.step()\r\n",
    "       \r\n",
    "        #Train Discriminator\r\n",
    "        real_loss=advloss_fn(discriminator(real_imgs), valid)\r\n",
    "        fake_loss=advloss_fn(discriminator(gen_imgs.detach()),fake)\r\n",
    "\r\n",
    "        d_loss=(real_loss+fake_loss)/2\r\n",
    "        dis_avgloss+=d_loss\r\n",
    "        d_loss.backward()\r\n",
    "        D_opt.step()\r\n",
    "    return gen_avgloss.item()/len(dataloader), dis_avgloss.item()/len(dataloader)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "for epoch in range(EPOCHS):\r\n",
    "    gen_avgloss, dis_avgloss=train_loop(train_loader, Generator, Discriminator, advloss_fn, G_opt, D_opt)\r\n",
    "    print(\r\n",
    "            \"[Epoch %d/%d]  [D loss: %f] [G loss: %f]\"\r\n",
    "            % (epoch, EPOCHS, dis_avgloss.item(), gen_avgloss.item())\r\n",
    "        )\r\n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "fill_() received an invalid combination of arguments - got (float, requires_grad=bool), but expected one of:\n * (Tensor value)\n * (Number value)\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-afabbdebc9be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mgen_avgloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdis_avgloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDiscriminator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madvloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mG_opt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD_opt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     print(\n\u001b[0;32m      4\u001b[0m             \u001b[1;34m\"[Epoch %d/%d]  [D loss: %f] [G loss: %f]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdis_avgloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgen_avgloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-76c7b3d4a4e1>\u001b[0m in \u001b[0;36mtrain_loop\u001b[1;34m(dataloader, generator, discriminator, advloss_fn, G_opt, D_opt)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mimgs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mvalid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mfake\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: fill_() received an invalid combination of arguments - got (float, requires_grad=bool), but expected one of:\n * (Tensor value)\n * (Number value)\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('pytorch_env': conda)"
  },
  "interpreter": {
   "hash": "dca4efdd400e53e6663797bbd1b46cf726b4dffb9a4cd6e80b88fc0d122f2781"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}