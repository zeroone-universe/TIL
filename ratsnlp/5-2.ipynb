{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ML-ubp246uzI"
      },
      "source": [
        "# 각종 설정\n",
        "모델 하이퍼파라메터(hyperparameter)와 저장 위치 등 설정 정보를 선언합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "dtoPBSH4v31j"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from ratsnlp.nlpbook.classification import ClassificationTrainArguments\n",
        "args = ClassificationTrainArguments(\n",
        "    pretrained_model_name=\"beomi/kcbert-base\",\n",
        "    downstream_task_name=\"pair-classification\",\n",
        "    downstream_corpus_name=\"klue-nli\",\n",
        "    downstream_corpus_root_dir='./5-2_content/Korpora',\n",
        "    # downstream_model_dir=\"/gdrive/My Drive/nlpbook/checkpoint-paircls\",\n",
        "    downstream_model_dir=\"./5-2_content/nlpbook/checkpoint-paircls\",\n",
        "    batch_size=32 if torch.cuda.is_available() else 4,\n",
        "    learning_rate=5e-5,\n",
        "    max_seq_length=64,\n",
        "    epochs=5,\n",
        "    tpu_cores=0 if torch.cuda.is_available() else 8,\n",
        "    seed=7,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48RjaTAr7D4M"
      },
      "source": [
        "# 랜덤 시드 고정\n",
        "학습 재현을 위해 랜덤 시드를 고정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "HuacSUSd7JRf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "set seed: 7\n"
          ]
        }
      ],
      "source": [
        "from ratsnlp import nlpbook\n",
        "nlpbook.set_seed(args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeTvf0bc9bbV"
      },
      "source": [
        "# 로거 설정\n",
        "메세지 출력 등을 위한 logger를 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "251gdehZ9iPZ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:ratsnlp:Training/evaluation parameters ClassificationTrainArguments(pretrained_model_name='beomi/kcbert-base', downstream_task_name='pair-classification', downstream_corpus_name='klue-nli', downstream_corpus_root_dir='./5-2_content/Korpora', downstream_model_dir='./5-2_content/nlpbook/checkpoint-paircls', max_seq_length=64, save_top_k=1, monitor='min val_loss', seed=7, overwrite_cache=False, force_download=False, test_mode=False, learning_rate=5e-05, epochs=5, batch_size=32, cpu_workers=16, fp16=False, tpu_cores=0)\n",
            "INFO:ratsnlp:Training/evaluation parameters ClassificationTrainArguments(pretrained_model_name='beomi/kcbert-base', downstream_task_name='pair-classification', downstream_corpus_name='klue-nli', downstream_corpus_root_dir='./5-2_content/Korpora', downstream_model_dir='./5-2_content/nlpbook/checkpoint-paircls', max_seq_length=64, save_top_k=1, monitor='min val_loss', seed=7, overwrite_cache=False, force_download=False, test_mode=False, learning_rate=5e-05, epochs=5, batch_size=32, cpu_workers=16, fp16=False, tpu_cores=0)\n",
            "INFO:ratsnlp:Training/evaluation parameters ClassificationTrainArguments(pretrained_model_name='beomi/kcbert-base', downstream_task_name='pair-classification', downstream_corpus_name='klue-nli', downstream_corpus_root_dir='./5-2_content/Korpora', downstream_model_dir='./5-2_content/nlpbook/checkpoint-paircls', max_seq_length=64, save_top_k=1, monitor='min val_loss', seed=7, overwrite_cache=False, force_download=False, test_mode=False, learning_rate=5e-05, epochs=5, batch_size=32, cpu_workers=16, fp16=False, tpu_cores=0)\n"
          ]
        }
      ],
      "source": [
        "nlpbook.set_logger(args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqUazvWL7Pry"
      },
      "source": [
        "# 말뭉치 다운로드\n",
        "실습에 사용할 말뭉치를 다운로드합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "opyaJgPA7Zxi"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:ratsnlp:cache file(/media/youngwon/Neo/NeoChoi/TIL/Pytorch-DL/ratsnlp/5-2_content/Korpora/klue-nli/klue_nli_train.json) exists, using cache!\n",
            "INFO:ratsnlp:cache file(/media/youngwon/Neo/NeoChoi/TIL/Pytorch-DL/ratsnlp/5-2_content/Korpora/klue-nli/klue_nli_train.json) exists, using cache!\n",
            "INFO:ratsnlp:cache file(/media/youngwon/Neo/NeoChoi/TIL/Pytorch-DL/ratsnlp/5-2_content/Korpora/klue-nli/klue_nli_train.json) exists, using cache!\n",
            "INFO:ratsnlp:cache file(/media/youngwon/Neo/NeoChoi/TIL/Pytorch-DL/ratsnlp/5-2_content/Korpora/klue-nli/klue_nli_dev.json) exists, using cache!\n",
            "INFO:ratsnlp:cache file(/media/youngwon/Neo/NeoChoi/TIL/Pytorch-DL/ratsnlp/5-2_content/Korpora/klue-nli/klue_nli_dev.json) exists, using cache!\n",
            "INFO:ratsnlp:cache file(/media/youngwon/Neo/NeoChoi/TIL/Pytorch-DL/ratsnlp/5-2_content/Korpora/klue-nli/klue_nli_dev.json) exists, using cache!\n"
          ]
        }
      ],
      "source": [
        "nlpbook.download_downstream_dataset(args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DnwLCKB7cRq"
      },
      "source": [
        "# 토크나이저 준비\n",
        "토큰화를 수행하는 토크나이저를 선언합니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "OlcoBivi7hIY"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\n",
        "    args.pretrained_model_name,\n",
        "    do_lower_case=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZbLCM5e7i6g"
      },
      "source": [
        "# 학습데이터 구축\n",
        "학습데이터를 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "v9s8znA17ovP"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:ratsnlp:Loading features from cached file ./5-2_content/Korpora/klue-nli/cached_train_BertTokenizer_64_klue-nli_pair-classification [took 0.643 s]\n",
            "INFO:ratsnlp:Loading features from cached file ./5-2_content/Korpora/klue-nli/cached_train_BertTokenizer_64_klue-nli_pair-classification [took 0.643 s]\n",
            "INFO:ratsnlp:Loading features from cached file ./5-2_content/Korpora/klue-nli/cached_train_BertTokenizer_64_klue-nli_pair-classification [took 0.643 s]\n"
          ]
        }
      ],
      "source": [
        "from ratsnlp.nlpbook.paircls import KlueNLICorpus\n",
        "from ratsnlp.nlpbook.classification import ClassificationDataset\n",
        "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler\n",
        "corpus = KlueNLICorpus()\n",
        "train_dataset = ClassificationDataset(\n",
        "    args=args,\n",
        "    corpus=corpus,\n",
        "    tokenizer=tokenizer,\n",
        "    mode=\"train\",\n",
        ")\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=args.batch_size,\n",
        "    sampler=RandomSampler(train_dataset, replacement=False),\n",
        "    collate_fn=nlpbook.data_collator,\n",
        "    drop_last=False,\n",
        "    num_workers=args.cpu_workers,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOAACuBY7vem"
      },
      "source": [
        "# 테스트 데이터 구축\n",
        "학습 중에 평가할 테스트 데이터를 구축합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "mcm1tgfq7y84"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:ratsnlp:Loading features from cached file ./5-2_content/Korpora/klue-nli/cached_test_BertTokenizer_64_klue-nli_pair-classification [took 0.053 s]\n",
            "INFO:ratsnlp:Loading features from cached file ./5-2_content/Korpora/klue-nli/cached_test_BertTokenizer_64_klue-nli_pair-classification [took 0.053 s]\n",
            "INFO:ratsnlp:Loading features from cached file ./5-2_content/Korpora/klue-nli/cached_test_BertTokenizer_64_klue-nli_pair-classification [took 0.053 s]\n"
          ]
        }
      ],
      "source": [
        "val_dataset = ClassificationDataset(\n",
        "    args=args,\n",
        "    corpus=corpus,\n",
        "    tokenizer=tokenizer,\n",
        "    mode=\"test\",\n",
        ")\n",
        "val_dataloader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=args.batch_size,\n",
        "    sampler=SequentialSampler(val_dataset),\n",
        "    collate_fn=nlpbook.data_collator,\n",
        "    drop_last=False,\n",
        "    num_workers=args.cpu_workers,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HztMCywb70e9"
      },
      "source": [
        "# 모델 초기화\n",
        "프리트레인이 완료된 BERT 모델을 읽고, 문서 쌍 분류를 수행할 모델을 초기화합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ohOlRdP18GVe"
      },
      "outputs": [],
      "source": [
        "from transformers import BertConfig, BertForSequenceClassification\n",
        "pretrained_model_config = BertConfig.from_pretrained(\n",
        "    args.pretrained_model_name,\n",
        "    num_labels=corpus.num_labels,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "staYwMx88MWQ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at beomi/kcbert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/kcbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "        args.pretrained_model_name,\n",
        "        config=pretrained_model_config,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYtJXijM8PN8"
      },
      "source": [
        "# 학습 준비\n",
        "Task와 Trainer를 준비합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "-FFn4MSz8SWu"
      },
      "outputs": [],
      "source": [
        "from ratsnlp.nlpbook.classification import ClassificationTask\n",
        "task = ClassificationTask(model, args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "18W4vRtR8UTx"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n"
          ]
        }
      ],
      "source": [
        "trainer = nlpbook.get_trainer(args)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KteHdhBT8X0e"
      },
      "source": [
        "# 학습\n",
        "준비한 데이터와 모델로 학습을 시작합니다. 학습 결과물(체크포인트)은 미리 연동해둔 구글 드라이브의 준비된 위치(`/gdrive/My Drive/nlpbook/checkpoint-paircls`)에 저장됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "SDr3M_nF8l7M"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Missing logger folder: /media/youngwon/Neo/NeoChoi/TIL/Pytorch-DL/ratsnlp/5-2_content/nlpbook/checkpoint-paircls/lightning_logs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/home/youngwon/anaconda3/envs/nlp_env/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py:380: RuntimeWarning: Found unsupported keys in the optimizer configuration: {'scheduler'}\n",
            "  rank_zero_warn(\n",
            "\n",
            "  | Name  | Type                          | Params\n",
            "--------------------------------------------------------\n",
            "0 | model | BertForSequenceClassification | 108 M \n",
            "--------------------------------------------------------\n",
            "108 M     Trainable params\n",
            "0         Non-trainable params\n",
            "108 M     Total params\n",
            "435.683   Total estimated model params size (MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4: 100%|██████████| 876/876 [05:31<00:00,  2.64it/s, loss=0.161, v_num=0, acc=1.000, val_loss=1.350, val_acc=0.665]  \n"
          ]
        }
      ],
      "source": [
        "trainer.fit(\n",
        "    task,\n",
        "    train_dataloaders=train_dataloader,\n",
        "    val_dataloaders=val_dataloader,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "pair-cls-train-colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
